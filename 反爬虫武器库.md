# 反爬虫武器库 - 2026年必备工具

## 立刻安装

```bash
# 方案1：Playwright（推荐）
pip install playwright
playwright install chromium

# 方案2：DrissionPage（国内友好）
pip install DrissionPage

# 方案3：终极武器
pip install undetected-chromedriver
```

## 快速模板（直接复制粘贴）

### Playwright模板（5分钟改好）

```python
from playwright.sync_api import sync_playwright
import pandas as pd

def scrape_with_playwright(url):
    with sync_playwright() as p:
        # 启动浏览器
        browser = p.chromium.launch(headless=False)  # headless=True 隐藏浏览器
        page = browser.new_page()
        
        # 访问网站
        page.goto(url)
        
        # 等待加载（根据实际情况调整）
        page.wait_for_selector('.product-item')  # 改成实际的CSS选择器
        
        # 提取数据
        items = page.query_selector_all('.product-item')[:10]  # 只抓10条样本
        data = []
        
        for item in items:
            try:
                title = item.query_selector('h3').inner_text()  # 改成实际选择器
                price = item.query_selector('.price').inner_text()  # 改成实际选择器
                
                data.append({
                    'title': title,
                    'price': price
                })
            except:
                continue
        
        browser.close()
        return data

# 使用
url = "https://目标网站.com"
data = scrape_with_playwright(url)

# 保存
df = pd.DataFrame(data)
df.to_csv('sample.csv', index=False)
print(f'抓取了 {len(data)} 条数据')
```

### DrissionPage模板（更简单）

```python
from DrissionPage import ChromiumPage
import pandas as pd

def scrape_with_drission(url):
    # 启动浏览器
    page = ChromiumPage()
    page.get(url)
    
    # 等待加载
    page.wait.load_start()
    
    # 提取数据
    items = page.eles('.product-item')[:10]  # 改成实际选择器
    data = []
    
    for item in items:
        try:
            title = item.ele('h3').text  # 改成实际选择器
            price = item.ele('.price').text  # 改成实际选择器
            
            data.append({
                'title': title,
                'price': price
            })
        except:
            continue
    
    page.quit()
    return data

# 使用
url = "https://目标网站.com"
data = scrape_with_drission(url)

# 保存
df = pd.DataFrame(data)
df.to_csv('sample.csv', index=False)
print(f'抓取了 {len(data)} 条数据')
```

## 常见问题快速解决

### 问题1：403 Forbidden
```python
# 不要用 requests，直接用浏览器自动化
# Playwright 或 DrissionPage 可以绕过大部分反爬
```

### 问题2：找不到元素
```python
# 加等待时间
page.wait_for_timeout(3000)  # 等3秒

# 或者等待特定元素
page.wait_for_selector('.product-item', timeout=10000)
```

### 问题3：动态加载
```python
# 滚动页面触发加载
page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
page.wait_for_timeout(2000)
```

### 问题4：需要点击"加载更多"
```python
# Playwright
page.click('button.load-more')
page.wait_for_timeout(2000)

# DrissionPage
page.ele('button.load-more').click()
page.wait(2)
```

## 竞标绝杀话术

```
Hi [Client Name],

I noticed the Cloudflare/anti-bot protection on [网站名], 
but my script has already bypassed it using browser automation.

✅ Attached: 10 real sample records from your target site
✅ Fields extracted: [列出字段名]
✅ Delivery: Complete dataset in 24 hours

Technical details:
- Using Playwright (not basic requests) to bypass protection
- Handling dynamic content and lazy loading
- Clean CSV output with UTF-8 encoding

Sample CSV attached shows this is real data, not dummy records.
Ready to start immediately.

Best,
[Your Name]
```

## 今晚行动清单

- [ ] 安装 Playwright: `pip install playwright && playwright install`
- [ ] 打开 Upwork，搜索 "web scraping"
- [ ] 找到第一个任务
- [ ] 用模板代码抓取10条样本
- [ ] 截图CSV文件
- [ ] 发送竞标（附样本）
- [ ] 重复以上步骤，发出20个竞标

## 记住

- ❌ 不要调试请求头（浪费时间）
- ❌ 不要追求完美代码（能跑就行）
- ✅ 遇到403直接换工具（Playwright）
- ✅ 5分钟搞不定就跳过（下一个任务）
- ✅ 饱和式攻击（发20+个竞标）

**现在立刻关闭这个文件，去Upwork发竞标！**

